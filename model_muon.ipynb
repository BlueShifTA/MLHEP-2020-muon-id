{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Coopetition - Muon id classification \n",
    "\n",
    "S. Ek-In, C. Praz\n",
    "\n",
    "\n",
    "[x] Select features and find new features \\\n",
    "[ ] Add Scaling to wide range variables \\\n",
    "[ ] CatBoost \\\n",
    "[x] Scale weight \n",
    "\n",
    "-> Need the module swifter with fsspec==0.3.3 , if the version is newer than this, the code might break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import part \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import utils\n",
    "import scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# The datasets are available in CoCalc in ~/share/data/I-coopetition-muon-id/\n",
    "# Test\n",
    "# ! wget --content-disposition https://codalab.coresearch.club/my/datasets/download/dd6255a1-a14b-4276-9a2b-db7f360e01c7\n",
    "# Train\n",
    "# ! wget --content-disposition https://codalab.coresearch.club/my/datasets/download/3a5e940c-2382-4716-9ff7-8fbc269b98ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "DATA_PATH = \"~/share/data/I-coopetition-muon-id/\"\n",
    "columns = utils.SIMPLE_FEATURE_COLUMNS + [\"id\", \"label\", \"weight\", \"sWeight\", \"kinWeight\"]\n",
    "train = utils.load_full_train_csv(DATA_PATH, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2 Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Main Setting \n",
    "\n",
    "weight_name = \"weight\"\n",
    "num_sample = 10\n",
    "train_vis = train.head(num_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "'''\n",
    "    Utils functions\n",
    "'''\n",
    "\n",
    "#classes = [0, 1]\n",
    "#columns = ['P', 'PT','ncl[0]', 'avg_cs[0]', 'ndof', 'MatchedHit_TYPE[0]', 'MatchedHit_TYPE[1]', 'MatchedHit_TYPE[2]']\n",
    "\n",
    "\n",
    "def visualize(feature, target, weights, num_bins=100):\n",
    "    classes = np.unique(target)\n",
    "    bins = np.linspace(feature.min(), feature.max(), num_bins + 1)\n",
    "    \n",
    "    # Plot all class \n",
    "    for c in classes:\n",
    "        selection = (target == c)\n",
    "        plt.hist(feature[selection], bins = bins, label = c, alpha = 0.5, weights = weights[selection])\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]', 'avg_cs[1]',\n",
      "       'avg_cs[2]', 'avg_cs[3]', 'ndof', 'MatchedHit_TYPE[0]',\n",
      "       'MatchedHit_TYPE[1]', 'MatchedHit_TYPE[2]', 'MatchedHit_TYPE[3]',\n",
      "       'MatchedHit_X[0]', 'MatchedHit_X[1]', 'MatchedHit_X[2]',\n",
      "       'MatchedHit_X[3]', 'MatchedHit_Y[0]', 'MatchedHit_Y[1]',\n",
      "       'MatchedHit_Y[2]', 'MatchedHit_Y[3]', 'MatchedHit_Z[0]',\n",
      "       'MatchedHit_Z[1]', 'MatchedHit_Z[2]', 'MatchedHit_Z[3]',\n",
      "       'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
      "       'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
      "       'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
      "       'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
      "       'MatchedHit_T[0]', 'MatchedHit_T[1]', 'MatchedHit_T[2]',\n",
      "       'MatchedHit_T[3]', 'MatchedHit_DT[0]', 'MatchedHit_DT[1]',\n",
      "       'MatchedHit_DT[2]', 'MatchedHit_DT[3]', 'Lextra_X[0]', 'Lextra_X[1]',\n",
      "       'Lextra_X[2]', 'Lextra_X[3]', 'Lextra_Y[0]', 'Lextra_Y[1]',\n",
      "       'Lextra_Y[2]', 'Lextra_Y[3]', 'NShared', 'Mextra_DX2[0]',\n",
      "       'Mextra_DX2[1]', 'Mextra_DX2[2]', 'Mextra_DX2[3]', 'Mextra_DY2[0]',\n",
      "       'Mextra_DY2[1]', 'Mextra_DY2[2]', 'Mextra_DY2[3]', 'FOI_hits_N',\n",
      "       'FOI_hits_X', 'FOI_hits_Y', 'FOI_hits_Z', 'FOI_hits_DX', 'FOI_hits_DY',\n",
      "       'FOI_hits_T', 'FOI_hits_S', 'PT', 'P', 'sWeight', 'label', 'kinWeight',\n",
      "       'weight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e0e8e3ace04f889af460aa63e24a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=100000.0, style=ProgressStyle(descript…"
      ]
     },
     "execution_count": 79,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking for high level parameters \n",
    "import swifter \n",
    "def Get_closest_hits(data):\n",
    "    \n",
    "    closest_hits_features = data.swifter.apply(utils.find_closest_hit_per_station, result_type=\"expand\", axis=1)\n",
    "    closest_hits_features.columns = [\"closest_{}\".format(ind) for ind in range(len(closest_hits_features.columns))]\n",
    "    \n",
    "    return closest_hits_features\n",
    "\n",
    "close_hits = Get_closest_hits(train)\n",
    "train_mod = pd.concat([train, close_hits], axis = 1)\n",
    "\n",
    "# Save to files for backing up\n",
    "close_hits.to_pickle('train_closest_hit.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Scale product of sWeight\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "def scale_sweight(data, edge_weight = 3):\n",
    "\n",
    "    data_mod = data[data['weight'].abs() < edge_weight]\n",
    "    data_mod['scale_weight'] = (data['weight'] + edge_weight)/(2 * edge_weight)\n",
    "    data_mod['scale_weight'] = data_mod['scale_weight'] * (data_mod['weight'].sum() / data_mod['scale_weight'].sum())\n",
    "    \n",
    "    return data_mod\n",
    "\n",
    "# Scale sweight\n",
    "train_mod = scale_sweight(train_mod, edge_weight = 3)\n",
    "    \n",
    "# Add new features \n",
    "def feat_PZ(data): \n",
    "    return np.sqrt(data['P'] ** 2  - data['PT'] ** 2)\n",
    "\n",
    "train_mod['PZ'] = feat_PZ(train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Visualisation \n",
    "\n",
    "for column in []:\n",
    "    plt.figure()\n",
    "    visualize(train[column][:num_sample], train['label'][:num_sample], train[weight_name][:num_sample])\n",
    "    plt.title(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Note: \n",
    " - Acc = 0.832126, train_cols with scaled sWeight, add PZ, Model: XGBoost LR = 0.1 [w/o close_hits]\n",
    " - Acc = 0.862225, train_cols with close_hits, scaled sWeight, add PZ, Model: XGBoost LR = 0.1 \n",
    " - Acc = 0.85      above with StandardScaler\n",
    " - Acc = 0.84      above with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Def used columns \n",
    "train_cols = ['ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]', 'avg_cs[1]',\n",
    "       'avg_cs[2]', 'avg_cs[3]', 'ndof', 'MatchedHit_TYPE[0]',\n",
    "       'MatchedHit_TYPE[1]', 'MatchedHit_TYPE[2]', 'MatchedHit_TYPE[3]',\n",
    "       'MatchedHit_X[0]', 'MatchedHit_X[1]', 'MatchedHit_X[2]',\n",
    "       'MatchedHit_X[3]', 'MatchedHit_Y[0]', 'MatchedHit_Y[1]',\n",
    "       'MatchedHit_Y[2]', 'MatchedHit_Y[3]', 'MatchedHit_Z[0]',\n",
    "       'MatchedHit_Z[1]', 'MatchedHit_Z[2]', 'MatchedHit_Z[3]',\n",
    "       'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
    "       'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
    "       'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
    "       'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
    "       'MatchedHit_T[0]', 'MatchedHit_T[1]', 'MatchedHit_T[2]',\n",
    "       'MatchedHit_T[3]', 'MatchedHit_DT[0]', 'MatchedHit_DT[1]',\n",
    "       'MatchedHit_DT[2]', 'MatchedHit_DT[3]', 'NShared', 'Mextra_DX2[0]',\n",
    "       'Mextra_DX2[1]', 'Mextra_DX2[2]', 'Mextra_DX2[3]', 'Mextra_DY2[0]',\n",
    "       'Mextra_DY2[1]', 'Mextra_DY2[2]', 'Mextra_DY2[3]', 'FOI_hits_N',\n",
    "       'PT', 'PZ'] + close_hits.columns.tolist()\n",
    "target_col = ['label', 'scale_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import re\n",
    "\n",
    "def prepare_data(data):\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in data.columns.values]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_val = scaler.transform(X_val)\\npca = PCA()\\nX_train = pca.fit_transform(X_train)\\nX_val = pca.transform(X_val)\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Heading data\n",
    "train.head()\n",
    "X_mod, y_mod = train_mod[train_cols], train_mod[target_col]\n",
    "\n",
    "# Rename - ignore [] \n",
    "prepare_data(X_mod)\n",
    "\n",
    "# Splitting \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_mod, y_mod, test_size=0.25, shuffle=True, random_state=2342234)\n",
    "\n",
    "\n",
    "\n",
    "# Scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ncl_0_  ncl_1_  ncl_2_  ncl_3_  avg_cs_0_  avg_cs_1_  avg_cs_2_  \\\n",
      "id                                                                       \n",
      "71891    73.0    13.0    12.0     8.0   2.041096   1.384615   1.083333   \n",
      "32976   146.0    36.0    38.0    20.0   3.130137   3.972222   2.026316   \n",
      "24461    53.0    21.0    18.0     9.0   2.301887   1.476190   1.500000   \n",
      "25203    31.0    22.0    12.0    13.0   1.870968   2.045455   2.333333   \n",
      "54940   151.0    15.0    10.0     9.0   3.039735   1.400000   1.600000   \n",
      "...       ...     ...     ...     ...        ...        ...        ...   \n",
      "96257    58.0    30.0     9.0     9.0   2.620690   1.833333   1.222222   \n",
      "54384    69.0     5.0    12.0    14.0   2.449275   1.000000   1.166667   \n",
      "15953   123.0    31.0    11.0    10.0   4.536585   2.258065   1.363636   \n",
      "7810    118.0    11.0    13.0    10.0   2.161017   4.909091   2.230769   \n",
      "99838    57.0    12.0     5.0    10.0   3.105263   2.416667   1.200000   \n",
      "\n",
      "       avg_cs_3_  ndof  MatchedHit_TYPE_0_  ...    closest_14    closest_15  \\\n",
      "id                                          ...                               \n",
      "71891   1.500000   8.0                 2.0  ...  17793.996094  19001.689453   \n",
      "32976   1.400000   8.0                 2.0  ...  17805.964844  19015.148438   \n",
      "24461   1.000000   8.0                 2.0  ...  17514.433594  18722.494141   \n",
      "25203   1.538462   8.0                 2.0  ...  17707.910156  18915.462891   \n",
      "54940   1.333333   8.0                 2.0  ...  17714.835938  18922.716797   \n",
      "...          ...   ...                 ...  ...           ...           ...   \n",
      "96257   1.222222   8.0                 2.0  ...  17804.041016  19012.814453   \n",
      "54384   1.571429   8.0                 2.0  ...  17716.880859  18925.041016   \n",
      "15953   1.300000   8.0                 2.0  ...  17518.677734  18727.423828   \n",
      "7810    1.300000   6.0                 2.0  ...  17719.125000   1000.000000   \n",
      "99838   1.300000   8.0                 2.0  ...  17593.882812  18917.832031   \n",
      "\n",
      "       closest_16  closest_17  closest_18   closest_19  closest_20  \\\n",
      "id                                                                   \n",
      "71891   12.750000   13.750000   59.000000    63.000000   63.078957   \n",
      "32976    3.208333    3.458333   14.833333    15.833333   15.679264   \n",
      "24461    6.375000    6.875000   29.500000    31.500000   31.479162   \n",
      "25203   25.500000   27.500000   59.000000    63.000000  126.278549   \n",
      "54940    3.208333    3.458333   14.833333    15.833333   15.679264   \n",
      "...           ...         ...         ...          ...         ...   \n",
      "96257   12.750000   13.750000   59.000000    63.000000   63.078957   \n",
      "54384   12.750000   13.750000   59.000000    63.000000   63.078957   \n",
      "15953    6.375000    6.875000   29.500000    31.500000   31.479162   \n",
      "7810     6.375000    3.458333   29.500000  1000.000000   31.479162   \n",
      "99838   25.500000   27.500000  118.000000   126.000000  126.278549   \n",
      "\n",
      "       closest_21  closest_22   closest_23  \n",
      "id                                          \n",
      "71891   68.078926   73.078896    78.078857  \n",
      "32976  136.278488   18.179249    19.429239  \n",
      "24461   33.979145   36.479130    38.979115  \n",
      "25203  136.278488   73.078896    78.078857  \n",
      "54940   16.929256   18.179249    19.429239  \n",
      "...           ...         ...          ...  \n",
      "96257   68.078926   73.078896    78.078857  \n",
      "54384   68.078926   73.078896    78.078857  \n",
      "15953   33.979145   36.479130    38.979115  \n",
      "7810    16.929256   36.479130  1000.000000  \n",
      "99838  136.278488  146.278412   156.278351  \n",
      "\n",
      "[45759 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3 Training part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Model Arch\n",
    "n_trees = 100\n",
    "model = xgboost.XGBClassifier(n_estimators = n_trees, nthread=-1, learning_rate = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning with lr = 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: 0.1 , Test accuracy: 0.8622258183427993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model_Best.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "# Trainning part\n",
    "\n",
    "score_best = 0\n",
    "model_best = None\n",
    "lr_best    = None\n",
    "\n",
    "lrs = [0.1]\n",
    "\n",
    "for lr in lrs:\n",
    "    print(\"trainning with lr = {}\".format(lr))\n",
    "    model = xgboost.XGBClassifier(n_estimators = n_trees, nthread=-1, learning_rate = lr)\n",
    "\n",
    "    model.fit(X_train.iloc[:, :],\n",
    "              y_train['label'].values,\n",
    "              sample_weight=y_train.scale_weight.values,\n",
    "              verbose=True,\n",
    "             )\n",
    "    ''' train with scaler and PCA \n",
    "    \n",
    "    model.fit(X_train,\n",
    "              y_train['label'].values,\n",
    "              sample_weight=y_train.scale_weight.values,\n",
    "              verbose=True,\n",
    "             )\n",
    "    '''\n",
    "    validation_predictions = model.predict_proba(X_val)[:, 1]\n",
    "    model_score = scoring.rejection90(y_val.label.values, validation_predictions, sample_weight = y_val.scale_weight.values)\n",
    "    print(\"NN: {} , Test accuracy: {}\".format(lr, model_score))\n",
    "    if model_score > score_best :\n",
    "        model_best = model\n",
    "        score_best = model_score\n",
    "        lr_best    = lr\n",
    "\n",
    "# Save Model \n",
    "joblib.dump(model_best, 'Model_Best.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622258183427993\n"
     ]
    }
   ],
   "source": [
    "print(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "validation_predictions = model.predict_proba(X_val)[:, 1]\n",
    "model_score = scoring.rejection90(y_val.label.values, validation_predictions, sample_weight = y_val.scale_weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622258183427993\n"
     ]
    }
   ],
   "source": [
    "print(model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4 Predict on the whole test set and prepare submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f51b388aa4da1ad3d9ebdb739f971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=100000.0, style=ProgressStyle(descript…"
      ]
     },
     "execution_count": 92,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read data\n",
    "\n",
    "test = utils.load_full_test_csv(DATA_PATH, None)\n",
    "\n",
    "\n",
    "# Transform data \n",
    "close_hits_test = Get_closest_hits(test)\n",
    "test_mod = pd.concat([test, close_hits_test], axis = 1)\n",
    "\n",
    "test_mod['PZ'] = feat_PZ(test_mod)\n",
    "X_test = test_mod[train_cols]\n",
    "prepare_data(X_test)\n",
    "\n",
    "\n",
    "# Predict and save file \n",
    "predictions = model_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='submission.csv')  \n",
    "pd.DataFrame(data={\"prediction\": predictions}, index=test.index).to_csv(\n",
    "    \"submission.zip\", index_label=utils.ID_COLUMN, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}